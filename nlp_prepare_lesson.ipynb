{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a8f7de",
   "metadata": {},
   "source": [
    "Run this command in your terminal! It downloads stopwords for the nltk library.\n",
    "\n",
    "python -c \"import nltk; nltk.download('stopwords')\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e866172b",
   "metadata": {},
   "source": [
    "Here we have some new imports! We will need unicodedata to standardize our text characters, re (regex library) to remove special characters, and many items from the nltk (natural language toolkit) library to remove stopwords and stem/lemmatize our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a89f03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08a78d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jongarcia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be67066",
   "metadata": {},
   "source": [
    "We will work with an explanation of string theory from my website. It has special characters and long words, which will help us visualize the effects our operations have on text data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "639db9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"Advanced: String theory is a mathematical framework that proposes to be a theory of quantum gravity, seeking to reconcile general relativity (which describes gravity on a large scale) and quantum mechanics (which describes the behavior of particles at a microscopic level). It introduces the idea that the fundamental building blocks of the universe are not particles, but rather one-dimensional strings of energy. These strings can vibrate at different frequencies, giving rise to different types of particles and forces. String theory also requires the existence of additional dimensions beyond the three spatial dimensions we are familiar with, which are compactified or curled up into tiny sizes.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0c6fa",
   "metadata": {},
   "source": [
    "Let's start off by converting all text to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab5249eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advanced: string theory is a mathematical framework that proposes to be a theory of quantum gravity,'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.lower()\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452f0b94",
   "metadata": {},
   "source": [
    "Now we can go through a series of steps to remove some special characters, such as accented characters in other languages. We may not see much of an effect with this particular example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e77460f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advanced: string theory is a mathematical framework that proposes to be a theory of quantum gravity,'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = unicodedata.normalize('NFKD', data)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417c4932",
   "metadata": {},
   "source": [
    "Let's use the regex library to substitute out all characters we don't want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9cc63c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advanced string theory is a mathematical framework that proposes to be a theory of quantum gravity s'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = re.sub(r\"[^a-z0-9'\\s]\", \"\", data)\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34d95995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(data):\n",
    "    # Convert the text to lowercase\n",
    "    data = data.lower()\n",
    "    \n",
    "    # Normalize the text by removing any diacritical marks\n",
    "    data = unicodedata.normalize('NFKD', data)\\\n",
    "        .encode('ascii', 'ignore')\\\n",
    "        .decode('utf-8', 'ignore')\n",
    "    \n",
    "    # Remove any characters that are not lowercase letters, numbers, apostrophes, or whitespaces\n",
    "    data = re.sub(r\"[^a-z0-9'\\s]\", \"\", data)\n",
    "    \n",
    "    # Return the cleaned data\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63a41825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advanced string theory is a mathematical framework that proposes to be a theory of quantum gravity s'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = basic_clean(data)\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3bd908",
   "metadata": {},
   "source": [
    "We can create an instance of the ToktokTokenizer object and use it to tokenize our data. This doesn't have a visual effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5d0aa78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advanced string theory is a mathematical framework that proposes to be a theory of quantum gravity s'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = ToktokTokenizer()\n",
    "\n",
    "data = tokenizer.tokenize(data, return_str=True)\n",
    "\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb444bf",
   "metadata": {},
   "source": [
    "Let's retrieve a list of stopwords from the nltk library. As you can see, the words in the stopwords list are common words we use in English, but they don't contribute much meaning to a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31af184a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d990bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['i', 'myself', 'we', 'our'], ['wouldn', \"wouldn't\", 'theory', 'framework'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra_words = ['theory', 'framework']\n",
    "# exclude_words = ['is', 'that']\n",
    "\n",
    "extra_words = ['theory', 'framework']\n",
    "exclude_words = ['me', 'my']\n",
    "\n",
    "stopwords_list.extend(extra_words)\n",
    "\n",
    "for word in exclude_words:\n",
    "    if word in stopwords_list:\n",
    "        stopwords_list.remove(word)\n",
    "\n",
    "\n",
    "stopwords_list[:4], stopwords_list[-4:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8739cc70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8723ef01",
   "metadata": {},
   "source": [
    "With a simple list comprehension, we can remove all words from our corpus that are found in the stopwords list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "978e28fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['advanced',\n",
       " 'string',\n",
       " 'theory',\n",
       " 'mathematical',\n",
       " 'framework',\n",
       " 'proposes',\n",
       " 'theory',\n",
       " 'quantum',\n",
       " 'gravity',\n",
       " 'seeking']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [word for word in data.split() if word not in stopwords_list]\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5db9dfa",
   "metadata": {},
   "source": [
    "We can use the .join() string method to recompile our words into a single string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40b2b73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advanced string theory mathematical framework proposes theory quantum gravity seeking reconcile gene'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = ' '.join(words)\n",
    "new_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    # Initialize a tokenizer object\n",
    "    tokenizer = ToktokTokenizer()\n",
    "\n",
    "    # Tokenize the input data using the tokenizer object\n",
    "    data = tokenizer.tokenize(data, return_str=True)\n",
    "\n",
    "    # Return the processed data\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa30915d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advanced string theory is a mathematical framework that proposes to be a theory of quantum gravity s'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = tokenize(data)\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0726bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(data):\n",
    "    # Create a list of stopwords in English\n",
    "    stopwords_list = stopwords.words('english')\n",
    "\n",
    "    # Split the data into individual words and filter out stopwords\n",
    "    words = [word for word in data.split() if word not in stopwords_list]\n",
    "    \n",
    "    # Join the filtered words back into a string\n",
    "    data = ' '.join(words)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "411eff96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advanced string theory mathematical framework proposes theory quantum gravity seeking reconcile gene'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = remove_stopwords(data)\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b65f557",
   "metadata": {},
   "source": [
    "We can create an instance of the PorterStemmer object and use it to stem our words. Note that many of the resulting words are not found in the dictionary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bafa5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advanc string theori mathemat framework propos theori quantum graviti seek reconcil gener rel descri'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "stems = [ps.stem(word) for word in words]\n",
    "\n",
    "stemmed_data = ' '.join(stems)\n",
    "\n",
    "stemmed_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "085a95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(data):\n",
    "    # Create an instance of the PorterStemmer class from the nltk library\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    # Create a list of words form data\n",
    "    words = data.split()\n",
    "    # Apply stemming to each word in the input data\n",
    "    stems = [ps.stem(word) for word in words]\n",
    "\n",
    "    # Join the stemmed words into a single string with spaces in between\n",
    "    stemmed_data = ' '.join(stems)\n",
    "\n",
    "    # Return the stemmed data\n",
    "    return stemmed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3755a99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advanc string theori mathemat framework propos theori quantum graviti seek reconcil gener rel descri'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = stem(data)\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fb2796",
   "metadata": {},
   "source": [
    "We can also use the WordNetLemmatizer. Note that it hardly changes text from its original form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b8cefb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advanced string theory mathematical framework proposes theory quantum gravity seeking reconcile gene'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "lemmas = [wnl.lemmatize(word) for word in words]\n",
    "\n",
    "lemmatized_data = ' '.join(lemmas)\n",
    "\n",
    "lemmatized_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da46fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(data):\n",
    "    # Create an instance of WordNetLemmatizer\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # Create a list of words form data\n",
    "    words = data.split()\n",
    "    \n",
    "    # Lemmatize each word in the input data\n",
    "    lemmas = [wnl.lemmatize(word) for word in words]\n",
    "\n",
    "    # Join the lemmatized words into a single string\n",
    "    lemmatized_data = ' '.join(lemmas)\n",
    "\n",
    "    # Return the lemmatized data\n",
    "    return lemmatized_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "402dfbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advanc string theori mathemat framework propos theori quantum graviti seek reconcil gener rel descri'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = lemmatize(data)\n",
    "data[:100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
